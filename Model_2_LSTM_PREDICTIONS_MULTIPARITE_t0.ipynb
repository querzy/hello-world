{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model 2 LSTM PREDICTIONS MULTIPARITE t0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdgnUWEv1FG4QZ1dkLFnAP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/querzy/hello-world/blob/master/Model_2_LSTM_PREDICTIONS_MULTIPARITE_t0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC_3XcQtgLEg"
      },
      "source": [
        "REINITIALISER L'ENVIRONNEMENT D'EXECUTION !!!\n",
        "- Execution - reinitialiser l'environnement d'execution\n",
        "- Executer le script plusieurs fois\n",
        "- Utiliser le dossier Oanda currency download2 (4000 barres)\n",
        "- Retirer une barre du fichier si barre ouverte et considérer le resultat à t0 OU considérer le résultat à t-1 avec une barre ouverte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR_OQSVeoDpO"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pVh13acoGP4"
      },
      "source": [
        "#@title\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from datetime import datetime\r\n",
        "from pandas.tseries.offsets import DateOffset\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        " \r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        " \r\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LSTM\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "#import chart_studio.plotly as py\r\n",
        "#import plotly.plotly as py\r\n",
        "import plotly.offline as pyoff\r\n",
        "import plotly.graph_objs as go\r\n",
        "#pyoff.init_notebook_mode(connected=True)\r\n",
        "from numpy.random import seed\r\n",
        "seed(1)\r\n",
        "tf.random.set_seed(2) \r\n",
        " \r\n",
        " \r\n",
        "#def parser(x):\r\n",
        "#    return pd.datetime.strptime('190'+x, '%Y-%m')\r\n",
        " \r\n",
        " \r\n",
        "#start='2020.08.21'\r\n",
        "#rng=pd.date_range(start, periods=5, freq='B').strftime('%Y-%m-%d 21:00:00')\r\n",
        "#df = pd.DataFrame({ 'date': rng, 'qty': np.random.randn(len(rng)) }) \r\n",
        " \r\n",
        "#plot daily prices\r\n",
        "#plot_data = [\r\n",
        "#    go.Scatter(\r\n",
        "#        x=df['date'],\r\n",
        "#        y=df['qty'],\r\n",
        "#    )\r\n",
        "#]\r\n",
        " \r\n",
        "#plot_layout = go.Layout(\r\n",
        "#        title='Daily Price'\r\n",
        "#    )\r\n",
        "#fig = go.Figure(data=plot_data, layout=plot_layout)\r\n",
        "#fig.show()\r\n",
        " \r\n",
        "def mean(numbers):\r\n",
        "    return float(sum(numbers)) / max(len(numbers), 1)\r\n",
        " \r\n",
        "def get_num(xx):\r\n",
        "    return int(''.join(ele for ele in xx if ele.isdigit()))\r\n",
        "\r\n",
        "\r\n",
        "with open('/content/recap deep learning t0.txt', 'w') as document: pass\r\n",
        "\r\n",
        "fileLst=['EURUSD1440.csv','EURUSD10080.csv','DOLLAR_INDX1440.csv','DOLLAR_INDX10080.csv','BTCUSD1440.csv','BTCUSD10080.csv'] \r\n",
        "  \r\n",
        "for k in fileLst :\r\n",
        "    filename1 = datetime.now().strftime(\"%d %b %Y - %H%M\")\r\n",
        "    filename=k.replace('.csv','')\r\n",
        "    filename= filename+' '+filename1\r\n",
        "    valperiod=get_num(k)\r\n",
        "    print(valperiod)\r\n",
        "    if valperiod==10080 :\r\n",
        "        TimeFrame = 'Weekly'\r\n",
        "        epochs=int(6)\r\n",
        "    elif valperiod==1440 :\r\n",
        "        TimeFrame = 'Daily'\r\n",
        "        epochs=int(5)\r\n",
        "    elif valperiod==240 :\r\n",
        "        TimeFrame = '4H'\r\n",
        "        epochs=int(3)\r\n",
        "    elif valperiod==60 :\r\n",
        "        TimeFrame = '1H'\r\n",
        "        epochs=int(6)\r\n",
        "    elif valperiod==15 :\r\n",
        "        TimeFrame = '15 min'\r\n",
        "        epochs=int(5)\r\n",
        " \r\n",
        "    t0up=0\r\n",
        "    t0dn=0 \r\n",
        "    PRICEAVt0=[]\r\n",
        "    PRICEAVupt0=[]\r\n",
        "    PRICEAVdnt0=[]\r\n",
        "    for j in range(20):\r\n",
        "      df = pd.read_csv(k, index_col='Date',usecols=['Date', 'Close'],date_parser = pd.to_datetime)\r\n",
        "      df.tail()\r\n",
        "     \r\n",
        "      print(df)\r\n",
        "     \r\n",
        "      train = df\r\n",
        "     \r\n",
        "      scaler = MinMaxScaler()\r\n",
        "      scaler.fit(train)\r\n",
        "      train = scaler.transform(train)\r\n",
        "     \r\n",
        "      n_input = 12\r\n",
        "      n_features = 1\r\n",
        "      generator = TimeseriesGenerator(train, train, length=n_input, batch_size=6)\r\n",
        "     \r\n",
        "      model = Sequential()\r\n",
        "      #model.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))\r\n",
        "      model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))\r\n",
        "      #model.add(Dropout(0.15))\r\n",
        "      model.add(Dense(1))\r\n",
        "     \r\n",
        "      #Model summary\r\n",
        "      #model.summary()\r\n",
        "      #Compiling\r\n",
        "      #model.compile(optimizer='adam', loss = 'mse')\r\n",
        "     \r\n",
        "      optimizer = keras.optimizers.Adam(learning_rate=0.001)\r\n",
        "      model.compile(optimizer=optimizer, loss='mse')\r\n",
        "     \r\n",
        "      history = model.fit(generator,epochs=5,verbose=1)#EURUSD\r\n",
        "      #history = model.fit(generator,epochs=20,verbose=1)#BTCUSD\r\n",
        "     \r\n",
        "      hist = pd.DataFrame(history.history)\r\n",
        "      hist['epoch'] = history.epoch\r\n",
        "     \r\n",
        "      plot_data = [\r\n",
        "          go.Scatter(\r\n",
        "              x=hist['epoch'],\r\n",
        "              y=hist['loss'],\r\n",
        "              name='loss'\r\n",
        "          )\r\n",
        "          \r\n",
        "      ]\r\n",
        "     \r\n",
        "      plot_layout = go.Layout(\r\n",
        "              title='Training loss'\r\n",
        "          )\r\n",
        "      fig = go.Figure(data=plot_data, layout=plot_layout)\r\n",
        "      #fig.show()\r\n",
        "      pyoff.iplot(fig)\r\n",
        "     \r\n",
        "      pred_list = []\r\n",
        "     \r\n",
        "      batch = train[-n_input:].reshape((1, n_input, n_features))\r\n",
        "     \r\n",
        "      for i in range(n_input):   \r\n",
        "          pred_list.append(model.predict(batch)[0]) \r\n",
        "          batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)\r\n",
        "     \r\n",
        "      if valperiod ==10080 :\r\n",
        "        add_dates = [df.index[-1] + DateOffset(weeks=x) for x in range(0,13) ]\r\n",
        "      elif valperiod ==1440 :\r\n",
        "        add_dates = [df.index[-1] + DateOffset(days=x) for x in range(0,13) ]\r\n",
        "      elif valperiod ==240 :\r\n",
        "        add_dates = [df.index[-1] + DateOffset(hours=x*4) for x in range(0,13) ]  \r\n",
        "      elif valperiod ==60 :\r\n",
        "        add_dates = [df.index[-1] + DateOffset(hours=x) for x in range(0,13) ] \r\n",
        "      #add_dates = [df.index[-1] + DateOffset(weeks=x) for x in range(0,13) ]\r\n",
        "      #add_dates = [df.index[-1] + DateOffset(days=x) for x in range(0,13) ]\r\n",
        "      #add_dates = [df.index[-1] + DateOffset(hours=x*4) for x in range(0,13) ]\r\n",
        "      \r\n",
        "      future_dates = pd.DataFrame(index=add_dates[1:],columns=df.columns)\r\n",
        "      print(add_dates)\r\n",
        "      df_predict = pd.DataFrame(scaler.inverse_transform(pred_list),\r\n",
        "                                index=future_dates[-n_input:].index, columns=['Prediction'])\r\n",
        "     \r\n",
        "      df_proj = pd.concat([df,df_predict], axis=1)\r\n",
        "     \r\n",
        "      df_proj.tail(12)\r\n",
        "     \r\n",
        "      plot_data = [\r\n",
        "          go.Scatter(\r\n",
        "              x=df_proj.index[-30:],\r\n",
        "              y=df_proj['Close'][-30:],\r\n",
        "              name='actual'\r\n",
        "          ),\r\n",
        "          go.Scatter(\r\n",
        "              x=df_proj.index[-30:],\r\n",
        "              y=df_proj['Prediction'][-30:],\r\n",
        "              name='prediction'\r\n",
        "          )\r\n",
        "      ]\r\n",
        "     \r\n",
        "      plot_layout = go.Layout(\r\n",
        "              title=k+' prediction t0'\r\n",
        "          )\r\n",
        "     \r\n",
        "      fig = go.Figure(data=plot_data, layout=plot_layout)\r\n",
        "      #fig.show()\r\n",
        "      pyoff.iplot(fig)\r\n",
        "      \r\n",
        "      \r\n",
        "      yt0Cl=df['Close'].iloc[-1]\r\n",
        "      yt0Pr=df_proj['Prediction'].iloc[-12]\r\n",
        "      PRICEAVt0.append(yt0Pr)\r\n",
        "      print(yt0Cl)\r\n",
        "      print(yt0Pr)\r\n",
        "      t0diff=yt0Cl-yt0Pr\r\n",
        "      if t0diff>0:\r\n",
        "        t0dn=t0dn+1\r\n",
        "        PRICEAVdnt0.append(yt0Pr)\r\n",
        "      elif t0diff<=0 :\r\n",
        "        t0up=t0up+1\r\n",
        "        PRICEAVupt0.append(yt0Pr)\r\n",
        "          \r\n",
        "    prixmoyt0=mean(PRICEAVt0)\r\n",
        "    prixmoydnt0=mean(PRICEAVdnt0)\r\n",
        "    prixmoyupt0=mean(PRICEAVupt0)\r\n",
        "\r\n",
        "     \r\n",
        "    \r\n",
        "    print(' ')\r\n",
        "    print('t0 :')\r\n",
        "    print(' ')\r\n",
        "    print('prix moyen t0 : ',prixmoyt0)\r\n",
        "    print(' ')\r\n",
        "    print('t0up : ',t0up)\r\n",
        "    print('prix moyen up t0 : ',prixmoyupt0)\r\n",
        "    print(' ')\r\n",
        "    print('t0dn : ',t0dn)\r\n",
        "    print('prix moyen dn t0 : ',prixmoydnt0)\r\n",
        "    print(' ')\r\n",
        "   \r\n",
        "\r\n",
        "    with open('/content/recap deep learning t0.txt', 'a') as f:\r\n",
        "        f.write(filename + '\\n')\r\n",
        "        f.write(' ' + '\\n')\r\n",
        "        f.write(' ' + '\\n')\r\n",
        "        f.write('t0 :'  + '\\n')\r\n",
        "        f.write(' '  + '\\n')\r\n",
        "        f.write('prix moyen t0 : '+str(prixmoyt0)  + '\\n') \r\n",
        "        f.write(' '  + '\\n')\r\n",
        "        f.write('t0up : '+str(t0up)  + '\\n')\r\n",
        "        f.write('prix moyen up t0 : '+str(prixmoyupt0)  + '\\n')\r\n",
        "        f.write(' '  + '\\n')\r\n",
        "        f.write('t0dn : '+str(t0dn)  + '\\n')\r\n",
        "        f.write('prix moyen dn t0 : '+str(prixmoydnt0)  + '\\n')\r\n",
        "        f.write(' '  + '\\n')\r\n",
        "        f.write('####################'  + '\\n')\r\n",
        "        f.write(' '  + '\\n')\r\n",
        "\r\n",
        "f.close()    \r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "files.download('/content/recap deep learning t0.txt')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}